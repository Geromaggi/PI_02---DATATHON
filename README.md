#                                         PROYECTO II DATA SCIENCE - DATATHON

![image](https://user-images.githubusercontent.com/93155829/199801185-4a4ffb2c-af31-491a-9475-d7a23787832e.png)

Hola! Bienvenidos al README que contiene una descripcion del proyecto realizado. 

# Consigna

El objetivo que teniamos que cumplir con este proyecto es, dado un conjunto de Datasets con informacion sobre propiedades en venta en Colombia, armar con diferentes algoritmos de Machine Learning, un modelo de clasificación que permita clasificar el precio de las propiedades en venta. Para esto, específicamente, debe predecir la categorización de las propiedades entre baratas o caras, considerando como criterio el valor promedio de los precios (la media).

Antes de armar nuestro modelo de machine learning, tambien fue necesario un preprocesamiento de los datos. Veamos a continuacion mas en detalle todo lo mencionado anteriormente. 

# Procedimiento

![image](https://user-images.githubusercontent.com/93155829/199806440-ae8edce0-2eb2-4f9c-b954-7c9792522b97.png)

Las herramientas usadas fueron Python (librerias como Pandas, numpy, skelearn, matplotlib, seaborn, geopandas, folium), Jupyter notebooks, etc. 
Con estas, fueron ingestados a nuestro sistemas los dos archivos .csv dados por el equipo de soyHenry (uno para el testeo, y otro para el entrenamiento). 

El preprocesamiento es uno de los estadios más importantes en el flujo de trabajo de un data scientist. Suele demandar, en promedio, entre el 60% y 70% de nuestro tiempo. La distinción entre un buen y un mal modelo de Machine Learning, antes que por la elección de un algoritmo específico, estará dada por un correcto preprocesamiento de datos.

Si queremos un modelo predictivo de calidad, debemos darle datos de calidad. Podemos elegir el algoritmo más sofisticado y complejo, optimizar los hiperparámetros tratando de encontrar las mejores combinaciones posibles, pero si al modelo lo alimentamos con datos que carecen de sentido, no podemos esperar que sus predicciones sí lo tengan.

El preprocesamiento de los datos tiene diferentes etapas que mas adelante veremos en detalle. Sin embargo, una instacia 'Cero' podriamos decirle es explorar el dataset. Esto quiere decir 

# FALTA TERMINAR!!!!!!!


